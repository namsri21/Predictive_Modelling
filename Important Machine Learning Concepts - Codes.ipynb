{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecbeb5e1",
   "metadata": {},
   "source": [
    "## LINEAR REGRESSION ASSUMPTION (MUTLICOLINEARITY) : VIF AUTOMATED CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a67f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from patsy import dmatrices\n",
    "\n",
    "variables_dropped=[]\n",
    "x=True\n",
    "while x:\n",
    "    ##Creating feature string for using it in VIF formula\n",
    "    column_str=''\n",
    "\n",
    "    for col in data_updated.columns.difference(['ln_SalePrice']):\n",
    "        column_str=column_str+col+'+'\n",
    "\n",
    "\n",
    "    formula=column_str[:-1]+'~ln_SalePrice'\n",
    "    X,Y=dmatrices(formula,data_updated,return_type='dataframe')\n",
    "    print('shape of X variable : ',X.shape)\n",
    "    print('shape of Y variable : ',Y.shape)\n",
    "    \n",
    "    \n",
    "    ## Calculate VIF\n",
    "    vif=pd.DataFrame()\n",
    "    vif['VIF_Factor']=[variance_inflation_factor(X.values,i) for i in range(X.shape[1])]\n",
    "    vif['Features']=X.columns\n",
    "\n",
    "    ##Sorting VIF from highest to lowest\n",
    "    vif.sort_values(by=['VIF_Factor'],ascending=[False],inplace=True)\n",
    "    vif=vif.reset_index()\n",
    "    vif.drop('index',axis=1,inplace=True)\n",
    "\n",
    "    ##Capturing variable for highest VIF\n",
    "    highest_vif=pd.DataFrame()\n",
    "    highest_vif=vif.loc[[0],:]\n",
    "    drop_var=highest_vif.Features[0]\n",
    "\n",
    "    ##Droppig variable with VIF>10 one by one\n",
    "    if(highest_vif.VIF_Factor[0]>10):\n",
    "            print('Variable Dropped : ',drop_var,' as its VIF is : ',highest_vif.VIF_Factor[0])\n",
    "            print('--------------------------------------')\n",
    "            variables_dropped.append(drop_var)\n",
    "            data_updated.drop(drop_var,axis=1,inplace=True)\n",
    "    else:\n",
    "            print('All Variables have VIF less than 10')\n",
    "            x=False\n",
    "            \n",
    "print(variables_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795abe1f",
   "metadata": {},
   "source": [
    "## LINEAR REGRESSION ASSUMPTION  : AUTOMATED CODE FOR CHECKING GRAPHICALLY WHETHER ALL NUMERICAL X VARIABLES ARE LINERARLY RELATED TO Y OR NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761eb112",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_num.columns.difference(['ln_SalePrice']):\n",
    "    sns.lmplot(x=col,y='ln_SalePrice',data=data_num,aspect=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf085b",
   "metadata": {},
   "source": [
    "## CATEGORICAL VARIABLE MISSING VALUE TREATMENT WITH MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c04b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing value treatment on Categorical Data\n",
    "\n",
    "def missing_value_cat(x):\n",
    "    x=x.fillna(x.mode().iloc[0])\n",
    "    return x\n",
    "\n",
    "data_cat=data_cat.apply(lambda x: missing_value_cat(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9083b3ec",
   "metadata": {},
   "source": [
    "## One hot Encoding for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(df,colname):\n",
    "    col_dummies=pd.get_dummies(df[colname],prefix=colname)\n",
    "    col_dummies.drop(col_dummies.columns[0],axis=1,inplace=True)\n",
    "    df=pd.concat([df,col_dummies],axis=1)\n",
    "    df.drop([colname],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "for features in data_cat.columns:\n",
    "    data_cat[features]=data_cat[features].astype('category')\n",
    "    data_cat=create_dummies(data_cat,features)\n",
    "    \n",
    "\n",
    "    \n",
    "data_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ca4d0",
   "metadata": {},
   "source": [
    "## NUMERICAL VARIABLE OUTILIER TREATMENT \n",
    "\n",
    "## NUMERICAL VARIABLE MISSING VALUE TREATMENT WITH MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7feef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we will do outlier treatment and then missing value treatment\n",
    "\n",
    "def outlier_clip(x):\n",
    "    x=x.clip(lower=x.quantile(0.01))\n",
    "    x=x.clip(upper=x.quantile(0.99))\n",
    "    return x\n",
    "\n",
    "data_num=data_num.apply(lambda x: outlier_clip(x))\n",
    "\n",
    "def missing_value(x):\n",
    "    x=x.fillna(x.mean())\n",
    "    x=x.fillna(x.mean())\n",
    "    return x\n",
    "\n",
    "data_num=data_num.apply(lambda x: missing_value(x))\n",
    "\n",
    "data_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8df9cd9",
   "metadata": {},
   "source": [
    "## Create log values of each varible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for col in data_num.columns:\n",
    "    data_num['ln_'+col]=np.log(data_num[col]+1)\n",
    "    \n",
    "    \n",
    "data_num.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d663f",
   "metadata": {},
   "source": [
    "## Creating Model and dropping Variables with p value greater than or equal to 0.05 one - by - one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31009f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_dropped_for_pvalue=[]\n",
    "\n",
    "x=True\n",
    "\n",
    "while x==True:\n",
    "\n",
    "    #creating model\n",
    "    linear_model=sm.OLS(Y_variable,X_variable).fit()\n",
    "    \n",
    "    #sorting p values high to low\n",
    "    pvaules_high_to_low=linear_model.pvalues.sort_values(ascending=False)\n",
    "    \n",
    "    #converting variable names as column\n",
    "    pvaules_high_to_low=pvaules_high_to_low.reset_index()\n",
    "    \n",
    "    #renaming columns\n",
    "    pvaules_high_to_low=pvaules_high_to_low.rename(columns={'index':'Variable_Name',0:'pvalue'})\n",
    "    \n",
    "    #CAPTURING HIGHEST PVALUE VARIABLE IN DATAFRAME\n",
    "    highest_pvalue=pd.DataFrame()\n",
    "    highest_pvalue=pvaules_high_to_low.loc[[0],:]\n",
    "    \n",
    "    ##Checking if pvalue is greater than or equal to 0.05 then droppping variable\n",
    "    if(highest_pvalue.pvalue[0]>=0.05):\n",
    "        print(highest_pvalue.Variable_Name[0],' has p _values : ',highest_pvalue.pvalue[0],' which is greater than 0.05')\n",
    "        variables_dropped_for_pvalue.append(highest_pvalue.Variable_Name[0])\n",
    "        X_variable.drop(highest_pvalue.Variable_Name[0],axis=1,inplace=True)\n",
    "        \n",
    "    else:\n",
    "        print('\\n')\n",
    "        print('Now All variables have p value less than 0.05')\n",
    "        x=False\n",
    "\n",
    "print(X_variable.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
